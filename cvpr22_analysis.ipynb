{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bEN9hWfZevX_"
   },
   "source": [
    "# Mask Convolutional Neural Network for Multi-level Hierarchical Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To be run on Google Colab!\n",
    "# !mkdir -p deakin/edu/au/\n",
    "# !wget --directory-prefix=deakin/edu/au/  https://raw.githubusercontent.com/rbouadjenek/Masked-CNN/main/deakin/edu/au/data.py   > /dev/null 2> /dev/null \n",
    "# !wget --directory-prefix=deakin/edu/au/ https://raw.githubusercontent.com/rbouadjenek/Masked-CNN/main/deakin/edu/au/metrics.py  > /dev/null 2> /dev/null \n",
    "# !wget --directory-prefix=deakin/edu/au/ https://raw.githubusercontent.com/rbouadjenek/Masked-CNN/main/deakin/edu/au/models.py  > /dev/null 2> /dev/null \n",
    "# !wget --directory-prefix=deakin/edu/au/ https://raw.githubusercontent.com/rbouadjenek/Masked-CNN/main/deakin/edu/au/__init__.py  > /dev/null 2> /dev/null \n",
    "# !wget --directory-prefix=deakin/edu/ https://raw.githubusercontent.com/rbouadjenek/Masked-CNN/main/deakin/edu/au/__init__.py  > /dev/null 2> /dev/null \n",
    "# !wget --directory-prefix=deakin/ https://raw.githubusercontent.com/rbouadjenek/Masked-CNN/main/deakin/edu/au/__init__.py  > /dev/null 2> /dev/null \n",
    "# !pip install treelib > /dev/null 2> /dev/null \n",
    "# !pip install --upgrade scikit-learn > /dev/null 2> /dev/null \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deakin.edu.au.data import Cifar100, Stanford_Cars, CU_Birds_200_2011\n",
    "from deakin.edu.au import models \n",
    "import deakin.edu.au.metrics as metrics\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import tensorflow as tf\n",
    "from graphviz import Digraph\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.applications import VGG19\n",
    "import random\n",
    "from tensorflow import keras\n",
    "import collections, h5py\n",
    "from tensorflow.python.keras.saving import hdf5_format\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sF_1dvCGevYB",
    "outputId": "042845cb-4427-42ec-ae72-3306cfc1d097"
   },
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "dataset = Cifar100()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford Cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "dataset = Stanford_Cars(image_size=(64,64))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CU_Birds_200_2011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load dataset\n",
    "dataset = CU_Birds_200_2011(image_size=(64,64))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the tree\n",
    "tree = dataset.get_tree()\n",
    "tree.show()\n",
    "# Set variables\n",
    "batch = 128\n",
    "epochs = 100\n",
    "# VGG-19\n",
    "conv_base = 'vgg19'\n",
    "learning_rate=1e-5\n",
    "# NIN\n",
    "# conv_base = 'nin'\n",
    "# learning_rate=1e-3\n",
    "\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "performance_callback_val = models.performance_callback(dataset.X_val, \n",
    "                                                       dataset.y_val, \n",
    "                                                       dataset.taxonomy, \n",
    "                                                       dataset.get_tree(),\n",
    "                                                       name='Validation set')\n",
    "\n",
    "performance_callback_train = models.performance_callback(dataset.X_train, \n",
    "                                                         dataset.y_train, \n",
    "                                                         dataset.taxonomy, \n",
    "                                                         dataset.get_tree(),\n",
    "                                                         name='Training set')\n",
    "\n",
    "checkpoint_filepath = '/tmp/checkpoint_new'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################\n",
    "#### Show distribution of images per class.\n",
    "###############################################\n",
    "counter=collections.Counter([x[0] for x in dataset.y_val[0]])\n",
    "v = [ [dataset.labels[0][item[0]],item[1]]  for item in counter.items()]\n",
    "df = pd.DataFrame(data=v, columns=['index','value'])\n",
    "g = sns.catplot(x='index', y= 'value',  data=df, kind='bar', \n",
    "                legend=False,height=4,aspect=4,saturation=1)\n",
    "(g.despine(top=False,right=False))\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"#images\")\n",
    "plt.title(\"Distribution of images per class for Level 0\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()\n",
    "###############################################\n",
    "#### Show distribution of images per class.\n",
    "###############################################\n",
    "counter=collections.Counter([x[0] for x in dataset.y_val[1]])\n",
    "v = [ [dataset.labels[1][item[0]],item[1]]  for item in counter.items()]\n",
    "df = pd.DataFrame(data=v, columns=['index','value'])\n",
    "g = sns.catplot(x='index', y= 'value',  data=df, kind='bar', \n",
    "                legend=False,height=4,aspect=4,saturation=1)\n",
    "(g.despine(top=False,right=False))\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"#images\")\n",
    "plt.title(\"Distribution of images per class for Level 0\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()\n",
    "###############################################\n",
    "#### Show distribution of images per class.\n",
    "###############################################\n",
    "counter=collections.Counter([x[0] for x in dataset.y_val[2]])\n",
    "v = [ [dataset.labels[2][item[0]],item[1]]  for item in counter.items()]\n",
    "df = pd.DataFrame(data=v, columns=['index','value'])\n",
    "g = sns.catplot(x='index', y= 'value',  data=df, kind='bar', \n",
    "                legend=False,height=4,aspect=4,saturation=1)\n",
    "(g.despine(top=False,right=False))\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"#images\")\n",
    "plt.title(\"Distribution of images per class for Level 0\")\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()\n",
    "###############################################\n",
    "#### Examples of images.\n",
    "###############################################\n",
    "\n",
    "plt.figure(figsize=(20, 16))\n",
    "for i in range(30):\n",
    "    k = random.randint(0, len(dataset.X_val))\n",
    "    file_name = dataset.val_filenames[k]\n",
    "    y_l0 = dataset.labels[0][dataset.y_val[0][k][0]]\n",
    "    y_l1 = dataset.labels[1][dataset.y_val[1][k][0]]\n",
    "    y_l2 = dataset.labels[2][dataset.y_val[2][k][0]]\n",
    "\n",
    "    ax = plt.subplot(5, 6, i + 1)\n",
    "    plt.imshow(dataset.X_val[k])\n",
    "    plt.title(file_name + \"\\n\" + y_l0 + \"\\n\" + y_l1 + \"\\n\" + y_l2)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_plots(history):\n",
    "    plt.figure(figsize=(15,4))\n",
    "    ax1 = plt.subplot(1, 2, 1)\n",
    "    for l in history.history:\n",
    "        if l == 'loss' or l == 'val_loss':  \n",
    "            loss = history.history[l]\n",
    "            plt.plot(range(1, len(loss) + 1), loss, label=l)\n",
    "\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    ax2 = plt.subplot(1, 2, 2)\n",
    "    for k in history.history:\n",
    "        if 'accuracy' in k:  \n",
    "            loss = history.history[k]\n",
    "            plt.plot(range(1, len(loss) + 1), loss, label=k)\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "mnets_model = models.get_mnets(dataset.num_classes, \n",
    "                               dataset.image_size, \n",
    "                               conv_base=conv_base,\n",
    "                               learning_rate=learning_rate)\n",
    "mnets_model.summary()\n",
    "#train model\n",
    "history_mnets_model = mnets_model.fit(dataset.X_train, \n",
    "                                      dataset.y_train,\n",
    "                                      validation_data = (dataset.X_val, dataset.y_val), \n",
    "                                      batch_size=batch, \n",
    "                                      epochs=epochs,\n",
    "                                      callbacks=[performance_callback_val, early_stopping_callback])\n",
    "learning_plots(history_mnets_model)\n",
    "mnets_model.save(\"models/mnets_model_\" + dataset.name + \"_\" + conv_base)\n",
    "plot_model(mnets_model)\n",
    "\n",
    "\n",
    "# with h5py.File(\"models/mnets_model_\" + dataset.name + \"_\" + conv_base + \"model.h5\", mode='w') as f:\n",
    "#     hdf5_format.save_model_to_hdf5(mnets_model, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnets_model_pred = mnets_model.predict(dataset.X_test)\n",
    "mnets_model_accuracy = metrics.get_top_k_taxonomical_accuracy(dataset.y_test, mnets_model_pred)\n",
    "mnets_model_accuracy = [x * 100 for x in mnets_model_accuracy]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potential_improvement(true_y, pred_y, taxo):\n",
    "    \n",
    "    pred_y = [np.argmax(x, axis=1) for x in pred_y]\n",
    "    oracle_accuracy1 = [0] * len(pred_y)\n",
    "    oracle_accuracy2 = [0] * len(pred_y)\n",
    "    oracle_accuracy = [0] * len(pred_y)\n",
    "    for i in range(len(pred_y)):\n",
    "        for j in range(len(pred_y[0])):\n",
    "            # check correctness\n",
    "            if pred_y[i][j] == true_y[i][j][0]:\n",
    "                continue\n",
    "            else:\n",
    "                # go left to right\n",
    "                stop = False\n",
    "                for z in range(i+1, len(pred_y)):\n",
    "                    if pred_y[z][j] == true_y[z][j][0]:\n",
    "                        oracle_accuracy[i] = oracle_accuracy[i] + 1\n",
    "                        oracle_accuracy1[i] = oracle_accuracy1[i] + 1\n",
    "                        stop = True\n",
    "                        break\n",
    "                #go right to left -- do not touch, complex code \n",
    "                if stop == False and i > 0:\n",
    "                    parents = []\n",
    "                    current = pred_y[i][j]\n",
    "                    for z in reversed(range(i)):\n",
    "                        m = taxo[z]\n",
    "                        row = list(np.transpose(m)[current])\n",
    "                        parent = row.index(1)\n",
    "                        current = parent\n",
    "                        parents.insert(0, parent)\n",
    "                    for z in reversed(range(i)):\n",
    "                        if pred_y[z][j] == true_y[z][j][0] and true_y[z][j][0] != parents[z]:\n",
    "                            oracle_accuracy[i] = oracle_accuracy[i] + 1\n",
    "                            oracle_accuracy2[i] = oracle_accuracy2[i] + 1\n",
    "                            break\n",
    "    \n",
    "    print(\"Total improvement: \",oracle_accuracy)\n",
    "    print(\"Left to right improvement: \",oracle_accuracy1)\n",
    "    print(\"Right to left improvement: \",oracle_accuracy2)\n",
    "    oracle_accuracy  = [x*100/len(mnets_model_pred[0]) for x in oracle_accuracy] \n",
    "    return oracle_accuracy\n",
    "\n",
    "\n",
    "# Testings\n",
    "# taxo = [[[1, 1, 0, 0, 0], [0, 0, 1, 1, 1]],\n",
    "#             [[1, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 1, 1, 0, 0, 0],\n",
    "#              [0, 0, 0, 0, 0, 0, 1, 1, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1]]\n",
    "#             ]\n",
    "# pred = [np.array([0]), np.array([1]),np.array([2])]\n",
    "# true_y = [np.array([[0]]), np.array([[0]]),np.array([[0]])]\n",
    "# get_potential_improvement(pred, true_y, taxo)\n",
    "\n",
    "# oracle_accuracy = get_potential_improvement(mnets_model_pred,\n",
    "#                                             dataset.y_test, \n",
    "#                                             dataset.taxonomy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_accuracy = get_potential_improvement(dataset.y_test, \n",
    "                                            mnets_model_pred,\n",
    "                                            dataset.taxonomy)\n",
    "\n",
    "labels = ['L0', 'L1', 'L2']\n",
    "width  = 0.6\n",
    "params = {'legend.fontsize': 10,\n",
    "          'axes.labelsize': 18,\n",
    "          'axes.titlesize': 11,\n",
    "          'xtick.labelsize': 14,\n",
    "          'ytick.labelsize': 14,\n",
    "          'axes.titlepad': 12}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "ax.set_axisbelow(True)\n",
    "ax.bar(labels, mnets_model_accuracy, width, edgecolor = 'black', linewidth = 0.5, color=['#FF3400','#0025FF','#008000','#FFFD07'])\n",
    "ax.bar(labels, oracle_accuracy, width,  bottom=mnets_model_accuracy, edgecolor = 'black', linewidth = 0.5, color=['#FFC0CB','#ADD8E6','#90EE90','#FFFEE0'])\n",
    "ax.set_ylabel('Fraction %')\n",
    "rects = ax.patches\n",
    "labels = [\"+%.2f\" % i for i in oracle_accuracy]\n",
    "labels = [x+\"%\" for x in labels]\n",
    "\n",
    "heights = []\n",
    "for imp, accuracy in zip(oracle_accuracy, mnets_model_accuracy):\n",
    "    heights.append(accuracy+imp/2)\n",
    " \n",
    "\n",
    "  \n",
    "for rect, label, height in zip(rects, labels,heights):\n",
    "    ax.text(rect.get_x() + rect.get_width() / 2, height-2, label,\n",
    "            ha='center', va='bottom')\n",
    "\n",
    "plt.yticks([10, 20, 30, 40, 50, 60, 70, 80, 90, 100])\n",
    "# ax.set_yticks([0,2,4,6])\n",
    "ax.set_ylim(0, 60)\n",
    "plt.grid(color = 'black', linestyle = '--', linewidth = 0.5)\n",
    "\n",
    "plt.savefig('plots/oracle_' + dataset.name + '_' + conv_base + '.eps', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "mout_model = models.get_mout_model(dataset.num_classes, \n",
    "                                   dataset.image_size, \n",
    "                                   conv_base=conv_base,\n",
    "                                   learning_rate=learning_rate)\n",
    "mout_model.summary()\n",
    "#train model\n",
    "history_mout_model = mout_model.fit(dataset.X_train, \n",
    "                                    dataset.y_train,\n",
    "                                    validation_data = (dataset.X_val, dataset.y_val),\n",
    "                                    batch_size=batch, \n",
    "                                    epochs=epochs,\n",
    "                                    callbacks=[performance_callback_val, early_stopping_callback])\n",
    "learning_plots(history_mout_model)\n",
    "mout_model.save(\"models/mout_model_\" + dataset.name + \"_\" + conv_base)\n",
    "plot_model(mout_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "BCNN1_model = models.get_BCNN1(dataset.num_classes, \n",
    "                               dataset.image_size, \n",
    "                               conv_base=conv_base,\n",
    "                               learning_rate=learning_rate)\n",
    "BCNN1_model.summary()\n",
    "#train model\n",
    "history_BCNN1_model = BCNN1_model.fit(dataset.X_train, \n",
    "                                      dataset.y_train,\n",
    "                                      validation_data = (dataset.X_val, dataset.y_val),\n",
    "                                      batch_size=batch, \n",
    "                                      epochs=epochs,\n",
    "                                      callbacks=[performance_callback_val, early_stopping_callback])\n",
    "learning_plots(history_BCNN1_model)\n",
    "BCNN1_model.save(\"models/BCNN1_model_\" + dataset.name + \"_\" + conv_base)\n",
    "plot_model(BCNN1_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "BCNN1_reversed_model = models.get_BCNN1(dataset.num_classes, \n",
    "                                        dataset.image_size, \n",
    "                                        reverse=True, \n",
    "                                        conv_base=conv_base, \n",
    "                                        learning_rate=learning_rate)\n",
    "BCNN1_reversed_model.summary()\n",
    "#train model\n",
    "history_BCNN1_reversed_model = BCNN1_reversed_model.fit(dataset.X_train, \n",
    "                                                        dataset.y_train,\n",
    "                                                        validation_data = (dataset.X_val, dataset.y_val),\n",
    "                                                        batch_size=batch, \n",
    "                                                        epochs=epochs,\n",
    "                                                        callbacks=[performance_callback_val, early_stopping_callback])\n",
    "learning_plots(history_BCNN1_reversed_model)\n",
    "BCNN1_reversed_model.save(\"models/BCNN1_reversed_model_\" + dataset.name + \"_\" + conv_base)\n",
    "plot_model(BCNN1_reversed_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "BCNN2_model = models.get_BCNN2(dataset.num_classes, \n",
    "                               dataset.image_size, \n",
    "                               conv_base=conv_base, \n",
    "                               learning_rate=learning_rate)\n",
    "BCNN2_model.summary()\n",
    "#train model\n",
    "history_BCNN2_model = BCNN2_model.fit(dataset.X_train, \n",
    "                                      dataset.y_train,\n",
    "                                      validation_data = (dataset.X_val, dataset.y_val), \n",
    "                                      batch_size=batch,\n",
    "                                      epochs=epochs,\n",
    "                                      callbacks=[performance_callback_val, early_stopping_callback])\n",
    "learning_plots(history_BCNN2_model)\n",
    "BCNN2_model.save(\"models/BCNN2_model_\" + dataset.name + \"_\" + conv_base)\n",
    "plot_model(BCNN2_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "BCNN2_reversed_model = models.get_BCNN2(dataset.num_classes, \n",
    "                                        dataset.image_size, \n",
    "                                        reverse=True, \n",
    "                                        conv_base=conv_base,\n",
    "                                        learning_rate=learning_rate)\n",
    "BCNN2_reversed_model.summary()\n",
    "#train model\n",
    "history_BCNN2_reversed_model = BCNN2_reversed_model.fit(dataset.X_train, \n",
    "                                                        dataset.y_train,\n",
    "                                                        validation_data = (dataset.X_val, dataset.y_val), \n",
    "                                                        batch_size=batch, \n",
    "                                                        epochs=epochs,\n",
    "                                                        callbacks=[performance_callback_val, early_stopping_callback])\n",
    "learning_plots(history_BCNN2_reversed_model)\n",
    "BCNN2_reversed_model.save(\"models/BCNN2_reversed_model_\" + dataset.name + \"_\" + conv_base)\n",
    "plot_model(BCNN2_reversed_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "MLPH_model = models.get_MLPH_model(dataset.num_classes, \n",
    "                                   dataset.image_size)\n",
    "MLPH_model.summary()\n",
    "#train model\n",
    "history_MLPH_model = MLPH_model.fit(dataset.X_train, \n",
    "                                    dataset.y_train,\n",
    "                                    validation_data = (dataset.X_val, dataset.y_val), \n",
    "                                    batch_size=batch, \n",
    "                                    epochs=epochs,\n",
    "                                    callbacks=[performance_callback_val, early_stopping_callback])\n",
    "learning_plots(history_MLPH_model)\n",
    "MLPH_model.save(\"models/MLPH_model_\" + dataset.name + \"_\" + conv_base)\n",
    "plot_model(MLPH_model,show_shapes=False, expand_nested=False, dpi=96)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "baseline_model = models.get_Baseline_model(dataset.num_classes, \n",
    "                                           dataset.image_size, \n",
    "                                           dataset.taxonomy, \n",
    "                                           conv_base=conv_base,\n",
    "                                           learning_rate=learning_rate)\n",
    "baseline_model.summary()\n",
    "#train model\n",
    "history_baseline_model = baseline_model.fit(dataset.X_train, \n",
    "                    dataset.y_train[-1],\n",
    "                    validation_data = (dataset.X_val, dataset.y_val[-1]),\n",
    "                    batch_size=batch, \n",
    "                    epochs=epochs,\n",
    "                    callbacks=[performance_callback_val, early_stopping_callback])\n",
    "learning_plots(history_baseline_model)\n",
    "baseline_model.save(\"models/baseline_model_\" + dataset.name + \"_\" + conv_base)\n",
    "plot_model(baseline_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tensorboard = TensorBoard(log_dir='/tmp/logs', histogram_freq=0,\n",
    "#                           write_graph=True, write_images=False)\n",
    "# Create the model\n",
    "mcnn_model = models.get_Masked_Output_Net(dataset.num_classes,\n",
    "                                          dataset.image_size,\n",
    "                                          dataset.taxonomy,\n",
    "                                          conv_base=conv_base,\n",
    "                                          learning_rate=learning_rate)\n",
    "mcnn_model.summary(line_length=110)\n",
    "#train model\n",
    "history_mcnn_model_model = mcnn_model.fit(dataset.X_train, \n",
    "                                          dataset.y_train,\n",
    "                                          validation_data = (dataset.X_val, dataset.y_val),\n",
    "                                          batch_size=batch, \n",
    "                                          epochs=epochs,\n",
    "                                          callbacks=[performance_callback_train,\n",
    "                                                     performance_callback_val, \n",
    "#                                                      tensorboard, \n",
    "                                                     early_stopping_callback\n",
    "                                                    ])\n",
    "learning_plots(history_mcnn_model_model)\n",
    "mcnn_model.save(\"models/mcnn_model_\" + dataset.name + \"_\" + conv_base)\n",
    "plot_model(mcnn_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "mcnn_mnets_model = models.get_Masked_Output_Net(dataset.num_classes,\n",
    "                                                dataset.image_size,\n",
    "                                                dataset.taxonomy,\n",
    "                                                conv_base=conv_base,\n",
    "                                                learning_rate=learning_rate,\n",
    "                                                mnets=True)\n",
    "mcnn_mnets_model.summary(line_length=110)\n",
    "#train model\n",
    "history_mcnn_mnets_model = mcnn_mnets_model.fit(dataset.X_train, \n",
    "                                                dataset.y_train,\n",
    "                                                validation_data=(dataset.X_val, dataset.y_val), \n",
    "                                                batch_size=batch, \n",
    "                                                epochs=epochs,\n",
    "                                                callbacks=[performance_callback_train,\n",
    "                                                           performance_callback_val,  \n",
    "#                                                            tensorboard, \n",
    "                                                           early_stopping_callback\n",
    "                                                          ])\n",
    "learning_plots(history_mcnn_mnets_model)\n",
    "mcnn_mnets_model.save(\"models/mcnn_mnets_model_\" + dataset.name + \"_\" + conv_base)\n",
    "plot_model(mcnn_mnets_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnn_model_pred = mcnn_model.predict(dataset.X_test)\n",
    "print(metrics.get_h_accuracy(dataset.y_test, mcnn_model_pred, k=2))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, mcnn_model_pred, k=3))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, mcnn_model_pred, k=4))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, mcnn_model_pred, k=5))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, mcnn_model_pred, k=6))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, mcnn_model_pred, k=7))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, mcnn_model_pred, k=8))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, mcnn_model_pred, k=9))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, mcnn_model_pred, k=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCNN2_reversed_pred = BCNN2_reversed_model.predict(dataset.X_test)\n",
    "print(metrics.get_h_accuracy(dataset.y_test, BCNN2_reversed_pred, k=2))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, BCNN2_reversed_pred, k=3))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, BCNN2_reversed_pred, k=4))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, BCNN2_reversed_pred, k=5))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, BCNN2_reversed_pred, k=6))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, BCNN2_reversed_pred, k=7))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, BCNN2_reversed_pred, k=8))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, BCNN2_reversed_pred, k=9))\n",
    "print(metrics.get_h_accuracy(dataset.y_test, BCNN2_reversed_pred, k=10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "mout_pred = mout_model.predict(dataset.X_test)\n",
    "BCNN1_pred = BCNN1_model.predict(dataset.X_test)\n",
    "BCNN1_reversed_pred = BCNN1_reversed_model.predict(dataset.X_test)\n",
    "BCNN2_pred = BCNN2_model.predict(dataset.X_test)\n",
    "BCNN2_reversed_pred = BCNN2_reversed_model.predict(dataset.X_test)\n",
    "mnets_pred = mnets_model.predict(dataset.X_test)\n",
    "baseline_pred = baseline_model.predict(dataset.X_test)\n",
    "MLPH_pred = MLPH_model.predict(dataset.X_test)\n",
    "mcnn_pred = mcnn_model.predict(dataset.X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_match_scores = [metrics.get_exact_match(dataset.y_test, mout_pred),\n",
    "                      metrics.get_exact_match(dataset.y_test, BCNN1_pred),\n",
    "                      metrics.get_exact_match(dataset.y_test, BCNN1_reversed_pred),\n",
    "                      metrics.get_exact_match(dataset.y_test, BCNN2_pred),\n",
    "                      metrics.get_exact_match(dataset.y_test, BCNN2_reversed_pred),\n",
    "                      metrics.get_exact_match(dataset.y_test, mnets_pred),\n",
    "                      metrics.get_exact_match(dataset.y_test, baseline_pred),\n",
    "                      metrics.get_exact_match(dataset.y_test, MLPH_pred),\n",
    "                      metrics.get_exact_match(dataset.y_test, mcnn_pred)]\n",
    "\n",
    "h_accuracy_scores = [metrics.get_h_accuracy(dataset.y_test, mout_pred),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, BCNN1_pred),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, BCNN1_reversed_pred),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, BCNN2_pred),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, BCNN2_reversed_pred),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, mnets_pred),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, baseline_pred), \n",
    "                     metrics.get_h_accuracy(dataset.y_test, MLPH_pred), \n",
    "                     metrics.get_h_accuracy(dataset.y_test, mcnn_pred)]\n",
    "\n",
    "h_accuracy_scores_k2 = [metrics.get_h_accuracy(dataset.y_test, mout_pred, k=2),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, BCNN1_pred, k=2),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, BCNN1_reversed_pred, k=2),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, BCNN2_pred, k=2),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, BCNN2_reversed_pred, k=2),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, mnets_pred, k=2),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, baseline_pred, k=2), \n",
    "                     metrics.get_h_accuracy(dataset.y_test, MLPH_pred, k=2), \n",
    "                     metrics.get_h_accuracy(dataset.y_test, mcnn_pred, k=2)]\n",
    "\n",
    "h_accuracy_scores_k5 = [metrics.get_h_accuracy(dataset.y_test, mout_pred, k=5),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, BCNN1_pred, k=5),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, BCNN1_reversed_pred, k=5),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, BCNN2_pred, k=5),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, BCNN2_reversed_pred, k=5),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, mnets_pred, k=5),\n",
    "                     metrics.get_h_accuracy(dataset.y_test, baseline_pred, k=5), \n",
    "                     metrics.get_h_accuracy(dataset.y_test, MLPH_pred, k=5), \n",
    "                     metrics.get_h_accuracy(dataset.y_test, mcnn_pred, k=5)]\n",
    "\n",
    "m_accuracy_scores = [metrics.get_m_accuracy(dataset.y_test, mout_pred),\n",
    "                     metrics.get_m_accuracy(dataset.y_test, BCNN1_pred),\n",
    "                     metrics.get_m_accuracy(dataset.y_test, BCNN1_reversed_pred),\n",
    "                     metrics.get_m_accuracy(dataset.y_test, BCNN2_pred),\n",
    "                     metrics.get_m_accuracy(dataset.y_test, BCNN2_reversed_pred),\n",
    "                     metrics.get_m_accuracy(dataset.y_test, mnets_pred),\n",
    "                     metrics.get_m_accuracy(dataset.y_test, baseline_pred),\n",
    "                     metrics.get_m_accuracy(dataset.y_test, MLPH_pred),\n",
    "                     metrics.get_m_accuracy(dataset.y_test, mcnn_pred)]\n",
    "\n",
    "\n",
    "consistency = [metrics.get_consistency(mout_pred, dataset.taxonomy),\n",
    "               metrics.get_consistency(BCNN1_pred, dataset.taxonomy),\n",
    "               metrics.get_consistency(BCNN1_reversed_pred, dataset.taxonomy),\n",
    "               metrics.get_consistency(BCNN2_pred, dataset.taxonomy),\n",
    "               metrics.get_consistency(BCNN2_reversed_pred, dataset.taxonomy),\n",
    "               metrics.get_consistency(mnets_pred, dataset.taxonomy),\n",
    "               metrics.get_consistency(baseline_pred, dataset.taxonomy),\n",
    "               metrics.get_consistency(MLPH_pred, dataset.taxonomy),\n",
    "               metrics.get_consistency(mcnn_pred, dataset.taxonomy)]\n",
    "\n",
    "# Create example dataframe\n",
    "df = pd.DataFrame({\n",
    "'exact_match': exact_match_scores,\n",
    "'h_accuracy': h_accuracy_scores,\n",
    "'h_accuracy_k2': h_accuracy_scores_k2,\n",
    "'h_accuracy_k5': h_accuracy_scores_k5,\n",
    "'m_accuracy': m_accuracy_scores,\n",
    "'consistency': consistency,\n",
    "'s': [3000,3000,3000,3000,3000,3000,3000,3000,3000],\n",
    "'algo': ['mout','BCNN1','BCNN1_R','BCNN2','BCNN2_R', 'mnets', 'baseline', 'MLPH', 'M-CNN']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.5, 4))\n",
    "params = {'legend.fontsize': 18,\n",
    "          'axes.labelsize': 20,\n",
    "          'axes.titlesize': 14,\n",
    "          'xtick.labelsize': 16,\n",
    "          'ytick.labelsize': 16,\n",
    "          'axes.titlepad': 25,\n",
    "          'font.size': 10}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "ax = sns.scatterplot(df.exact_match, df.consistency, alpha = 0.5,s = df.s)\n",
    "\n",
    "ax.grid(color='black', linestyle='--', linewidth=1)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"consistency\")\n",
    "# plt.title(\"Box plot of #candidates per cycle and system\")\n",
    "plt.yticks([0.2,0.4,0.6,0.8,1.0])\n",
    "plt.xticks([0.0,0.2,0.4,0.6,0.8,1.0])\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "plt.xlabel('Exact Match')\n",
    "plt.ylabel('Consistency')\n",
    "#For each point, we add a text inside the bubble\n",
    "for line in range(0,df.shape[0]):\n",
    "    if df.algo[line]=='baseline':\n",
    "        ax.text(df.exact_match[line], df.consistency[line], df.algo[line], verticalalignment='top', horizontalalignment='center', size='medium', color='black', weight='semibold')\n",
    "    elif df.algo[line].startswith('BCNN'):\n",
    "        ax.text(df.exact_match[line], df.consistency[line], df.algo[line], horizontalalignment='left', size='medium', color='black', weight='semibold')\n",
    "    else:\n",
    "        ax.text(df.exact_match[line], df.consistency[line], df.algo[line], horizontalalignment='center', size='medium', color='black', weight='semibold')\n",
    "\n",
    "\n",
    "\n",
    "currentAxis = plt.gca()\n",
    "currentAxis.add_patch(Rectangle((0., 0.), 1., 0.2, color = 'red', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0., 0.), .2, 1., color = 'red',zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.2, 0.2), 0.2, 0.2, color = 'red', zorder=0))\n",
    "\n",
    "currentAxis.add_patch(Rectangle((0.2, 0.4), 0.4, 1.0, color = 'orange', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.4, 0.2), 1., 0.4, color = 'orange', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.6, 0.6), 0.2, 0.2, color = 'orange', zorder=0))\n",
    "\n",
    "currentAxis.add_patch(Rectangle((0.8, 0.6), 0.2, 0.4, color = 'green', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.6, 0.8), 0.4, 0.2, color = 'green', zorder=0))\n",
    "# plotlim = plt.xlim() + plt.ylim()\n",
    "# import matplotlib.colors\n",
    "\n",
    "# cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"yellow\",\"green\"])\n",
    "\n",
    "# ax.imshow([[0.5, 0.5, 0.5], [0, 0.5, 0.5], [0, 0, 0.5]],\n",
    "#           cmap=cmap,\n",
    "#           interpolation='bicubic',\n",
    "#           extent=plotlim, vmin=0, vmax=0.5)\n",
    "        \n",
    "plt.savefig('plots/bubble_plot_em.pdf', bbox_inches = 'tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "X9MHRySfoNS2",
    "outputId": "c6ec66c8-0988-412c-e3ef-08e3841510e5"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.5, 4))\n",
    "params = {'legend.fontsize': 18,\n",
    "          'axes.labelsize': 20,\n",
    "          'axes.titlesize': 14,\n",
    "          'xtick.labelsize': 16,\n",
    "          'ytick.labelsize': 16,\n",
    "          'axes.titlepad': 25,\n",
    "          'font.size': 10}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "ax = sns.scatterplot(df.h_accuracy, df.consistency, alpha = 0.5,s = df.s)\n",
    "\n",
    "ax.grid(color='black', linestyle='--', linewidth=1)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"consistency\")\n",
    "# plt.title(\"Box plot of #candidates per cycle and system\")\n",
    "plt.yticks([0.2,0.4,0.6,0.8,1.0])\n",
    "plt.xticks([0.0,0.2,0.4,0.6,0.8,1.0])\n",
    "\n",
    "ax.set_xlim(0, 1)\n",
    "ax.set_ylim(0, 1)\n",
    "plt.xlabel('Harmonic Accuracy')\n",
    "plt.ylabel('Consistency')\n",
    "#For each point, we add a text inside the bubble\n",
    "for line in range(0,df.shape[0]):\n",
    "    if df.algo[line]=='baseline':\n",
    "        ax.text(df.h_accuracy[line], df.consistency[line], df.algo[line], verticalalignment='top', horizontalalignment='center', size='medium', color='black', weight='semibold')\n",
    "    elif df.algo[line].startswith('BCNN'):\n",
    "        ax.text(df.h_accuracy[line], df.consistency[line], df.algo[line], horizontalalignment='left', size='medium', color='black', weight='semibold')\n",
    "    else:\n",
    "        ax.text(df.h_accuracy[line], df.consistency[line], df.algo[line], horizontalalignment='center', size='medium', color='black', weight='semibold')\n",
    "\n",
    "\n",
    "\n",
    "currentAxis = plt.gca()\n",
    "currentAxis.add_patch(Rectangle((0., 0.), 1., 0.2, color = 'red', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0., 0.), .2, 1., color = 'red',zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.2, 0.2), 0.2, 0.2, color = 'red', zorder=0))\n",
    "\n",
    "currentAxis.add_patch(Rectangle((0.2, 0.4), 0.4, 1.0, color = 'orange', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.4, 0.2), 1., 0.4, color = 'orange', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.6, 0.6), 0.2, 0.2, color = 'orange', zorder=0))\n",
    "\n",
    "currentAxis.add_patch(Rectangle((0.8, 0.6), 0.2, 0.4, color = 'green', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.6, 0.8), 0.4, 0.2, color = 'green', zorder=0))\n",
    "# plotlim = plt.xlim() + plt.ylim()\n",
    "# import matplotlib.colors\n",
    "\n",
    "# cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"yellow\",\"green\"])\n",
    "\n",
    "# ax.imshow([[0.5, 0.5, 0.5], [0, 0.5, 0.5], [0, 0, 0.5]],\n",
    "#           cmap=cmap,\n",
    "#           interpolation='bicubic',\n",
    "#           extent=plotlim, vmin=0, vmax=0.5)\n",
    "        \n",
    "plt.savefig('plots/bubble_plot_h_accuracy.pdf', bbox_inches = 'tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.5, 4))\n",
    "params = {'legend.fontsize': 18,\n",
    "          'axes.labelsize': 20,\n",
    "          'axes.titlesize': 14,\n",
    "          'xtick.labelsize': 16,\n",
    "          'ytick.labelsize': 16,\n",
    "          'axes.titlepad': 25,\n",
    "          'font.size': 10}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "ax = sns.scatterplot(df.h_accuracy_k2, df.consistency, alpha = 0.5,s = df.s)\n",
    "\n",
    "ax.grid(color='black', linestyle='--', linewidth=1)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"consistency\")\n",
    "# plt.title(\"Box plot of #candidates per cycle and system\")\n",
    "plt.yticks([0.2,0.4,0.6,0.8,1.0])\n",
    "plt.xticks([0.0,0.2,0.4,0.6,0.8,1.0])\n",
    "\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_ylim(0, 1)\n",
    "plt.xlabel('Harmonic Accuracy k=2')\n",
    "plt.ylabel('Consistency')\n",
    "#For each point, we add a text inside the bubble\n",
    "for line in range(0,df.shape[0]):\n",
    "    if df.algo[line]=='baseline':\n",
    "        ax.text(df.h_accuracy_k2[line], df.consistency[line], df.algo[line], verticalalignment='top', horizontalalignment='center', size='medium', color='black', weight='semibold')\n",
    "    elif df.algo[line].startswith('BCNN'):\n",
    "        ax.text(df.h_accuracy_k2[line], df.consistency[line], df.algo[line], horizontalalignment='left', size='medium', color='black', weight='semibold')\n",
    "    else:\n",
    "        ax.text(df.h_accuracy_k2[line], df.consistency[line], df.algo[line], horizontalalignment='center', size='medium', color='black', weight='semibold')\n",
    "\n",
    "\n",
    "\n",
    "currentAxis = plt.gca()\n",
    "currentAxis.add_patch(Rectangle((0., 0.), 1., 0.2, color = 'red', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0., 0.), .2, 1., color = 'red',zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.2, 0.2), 0.2, 0.2, color = 'red', zorder=0))\n",
    "\n",
    "currentAxis.add_patch(Rectangle((0.2, 0.4), 0.4, 1.0, color = 'orange', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.4, 0.2), 1., 0.4, color = 'orange', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.6, 0.6), 0.2, 0.2, color = 'orange', zorder=0))\n",
    "\n",
    "currentAxis.add_patch(Rectangle((0.8, 0.6), 0.2, 0.4, color = 'green', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.6, 0.8), 0.4, 0.2, color = 'green', zorder=0))\n",
    "# plotlim = plt.xlim() + plt.ylim()\n",
    "# import matplotlib.colors\n",
    "\n",
    "# cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"yellow\",\"green\"])\n",
    "\n",
    "# ax.imshow([[0.5, 0.5, 0.5], [0, 0.5, 0.5], [0, 0, 0.5]],\n",
    "#           cmap=cmap,\n",
    "#           interpolation='bicubic',\n",
    "#           extent=plotlim, vmin=0, vmax=0.5)\n",
    "        \n",
    "plt.savefig('plots/bubble_plot_h_accuracy_k2.pdf', bbox_inches = 'tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.5, 4))\n",
    "params = {'legend.fontsize': 18,\n",
    "          'axes.labelsize': 20,\n",
    "          'axes.titlesize': 14,\n",
    "          'xtick.labelsize': 16,\n",
    "          'ytick.labelsize': 16,\n",
    "          'axes.titlepad': 25,\n",
    "          'font.size': 10}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "ax = sns.scatterplot(df.h_accuracy_k5, df.consistency, alpha = 0.5,s = df.s)\n",
    "\n",
    "ax.grid(color='black', linestyle='--', linewidth=1)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"consistency\")\n",
    "# plt.title(\"Box plot of #candidates per cycle and system\")\n",
    "plt.yticks([0.2,0.4,0.6,0.8,1.0])\n",
    "plt.xticks([0.0,0.2,0.4,0.6,0.8,1.0])\n",
    "\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_ylim(0, 1)\n",
    "plt.xlabel('Harmonic Accuracy k=5')\n",
    "plt.ylabel('Consistency')\n",
    "#For each point, we add a text inside the bubble\n",
    "for line in range(0,df.shape[0]):\n",
    "    if df.algo[line]=='baseline':\n",
    "        ax.text(df.h_accuracy_k5[line], df.consistency[line], df.algo[line], verticalalignment='top', horizontalalignment='center', size='medium', color='black', weight='semibold')\n",
    "    elif df.algo[line].startswith('BCNN'):\n",
    "        ax.text(df.h_accuracy_k5[line], df.consistency[line], df.algo[line], horizontalalignment='left', size='medium', color='black', weight='semibold')\n",
    "    else:\n",
    "        ax.text(df.h_accuracy_k5[line], df.consistency[line], df.algo[line], horizontalalignment='center', size='medium', color='black', weight='semibold')\n",
    "\n",
    "\n",
    "\n",
    "currentAxis = plt.gca()\n",
    "currentAxis.add_patch(Rectangle((0., 0.), 1., 0.2, color = 'red', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0., 0.), .2, 1., color = 'red',zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.2, 0.2), 0.2, 0.2, color = 'red', zorder=0))\n",
    "\n",
    "currentAxis.add_patch(Rectangle((0.2, 0.4), 0.4, 1.0, color = 'orange', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.4, 0.2), 1., 0.4, color = 'orange', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.6, 0.6), 0.2, 0.2, color = 'orange', zorder=0))\n",
    "\n",
    "currentAxis.add_patch(Rectangle((0.8, 0.6), 0.2, 0.4, color = 'green', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.6, 0.8), 0.4, 0.2, color = 'green', zorder=0))\n",
    "# plotlim = plt.xlim() + plt.ylim()\n",
    "# import matplotlib.colors\n",
    "\n",
    "# cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"yellow\",\"green\"])\n",
    "\n",
    "# ax.imshow([[0.5, 0.5, 0.5], [0, 0.5, 0.5], [0, 0, 0.5]],\n",
    "#           cmap=cmap,\n",
    "#           interpolation='bicubic',\n",
    "#           extent=plotlim, vmin=0, vmax=0.5)\n",
    "        \n",
    "plt.savefig('plots/bubble_plot_h_accuracy_k5.pdf', bbox_inches = 'tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "T7kX_iQsoNb1",
    "outputId": "07fb39f4-983b-4ef1-d99f-9db29f7622e0"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6.5, 4))\n",
    "params = {'legend.fontsize': 18,\n",
    "          'axes.labelsize': 20,\n",
    "          'axes.titlesize': 14,\n",
    "          'xtick.labelsize': 16,\n",
    "          'ytick.labelsize': 16,\n",
    "          'axes.titlepad': 25,\n",
    "          'font.size': 10}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "ax = sns.scatterplot(df.m_accuracy, df.consistency, alpha = 0.5,s = df.s)\n",
    "\n",
    "ax.grid(color='black', linestyle='--', linewidth=1)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "plt.xlabel(\"\")\n",
    "plt.ylabel(\"consistency\")\n",
    "# plt.title(\"Box plot of #candidates per cycle and system\")\n",
    "plt.yticks([0.2,0.4,0.6,0.8,1.0])\n",
    "plt.xticks([0.0,0.2,0.4,0.6,0.8,1.0])\n",
    "\n",
    "ax.set_xlim(0,1)\n",
    "ax.set_ylim(0, 1)\n",
    "plt.xlabel('Mean Accuracy')\n",
    "plt.ylabel('Consistency')\n",
    "#For each point, we add a text inside the bubble\n",
    "for line in range(0,df.shape[0]):\n",
    "    if df.algo[line]=='baseline':\n",
    "        ax.text(df.m_accuracy[line], df.consistency[line], df.algo[line], verticalalignment='top', horizontalalignment='center', size='medium', color='black', weight='semibold')\n",
    "    elif df.algo[line].startswith('BCNN'):\n",
    "        ax.text(df.m_accuracy[line], df.consistency[line], df.algo[line], horizontalalignment='left', size='medium', color='black', weight='semibold')\n",
    "    else:\n",
    "        ax.text(df.m_accuracy[line], df.consistency[line], df.algo[line], horizontalalignment='center', size='medium', color='black', weight='semibold')\n",
    "\n",
    "\n",
    "\n",
    "currentAxis = plt.gca()\n",
    "currentAxis.add_patch(Rectangle((0., 0.), 1., 0.2, color = 'red', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0., 0.), .2, 1., color = 'red',zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.2, 0.2), 0.2, 0.2, color = 'red', zorder=0))\n",
    "\n",
    "currentAxis.add_patch(Rectangle((0.2, 0.4), 0.4, 1.0, color = 'orange', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.4, 0.2), 1., 0.4, color = 'orange', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.6, 0.6), 0.2, 0.2, color = 'orange', zorder=0))\n",
    "\n",
    "currentAxis.add_patch(Rectangle((0.8, 0.6), 0.2, 0.4, color = 'green', zorder=0))\n",
    "currentAxis.add_patch(Rectangle((0.6, 0.8), 0.4, 0.2, color = 'green', zorder=0))\n",
    "# plotlim = plt.xlim() + plt.ylim()\n",
    "# import matplotlib.colors\n",
    "\n",
    "# cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"red\",\"yellow\",\"green\"])\n",
    "\n",
    "# ax.imshow([[0.5, 0.5, 0.5], [0, 0.5, 0.5], [0, 0, 0.5]],\n",
    "#           cmap=cmap,\n",
    "#           interpolation='bicubic',\n",
    "#           extent=plotlim, vmin=0, vmax=0.5)\n",
    "        \n",
    "plt.savefig('plots/bubble_plot_m_accuracy.pdf', bbox_inches = 'tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This section is used for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "i = 2\n",
    "baseline_model = m.get_Classifier_model(num_classes[i], \n",
    "                                           dataset.image_size, \n",
    "                                           conv_base='vgg19',\n",
    "                                           learning_rate=1e-5,\n",
    "                                            lam=0.0001)\n",
    "baseline_model.summary()\n",
    "#train model\n",
    "history_baseline_model = baseline_model.fit(dataset.X_train, \n",
    "                    dataset.y_train[i],\n",
    "                    validation_data = (dataset.X_val, dataset.y_val[i]),\n",
    "                    batch_size=batch, \n",
    "                    epochs=200,\n",
    "                    )\n",
    "plot_model(baseline_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dropout, Flatten, Dense, Activation, Lambda, Conv2D, MaxPool2D, \\\n",
    "    GlobalAveragePooling2D, Multiply, Concatenate, experimental\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import VGG19, VGG16, ResNet50, Xception\n",
    "\n",
    "\n",
    "i = 2\n",
    "in_layer = Input(shape=dataset.image_size)\n",
    "rescale = experimental.preprocessing.Rescaling(1. / 255)(in_layer)\n",
    "conv_base = VGG19(include_top=False, weights=\"imagenet\")(rescale)\n",
    "conv_base = Flatten()(conv_base)\n",
    "# create output layers\n",
    "out_layer = Dense(num_classes[i], activation=\"softmax\")(conv_base)\n",
    "# Build the model\n",
    "model = Model(inputs=in_layer,\n",
    "              outputs=out_layer)\n",
    "loss = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "history_baseline_model = model.fit(dataset.X_val, \n",
    "                    dataset.y_val[i],\n",
    "                    validation_data = (dataset.X_val, dataset.y_val[i]),\n",
    "                    batch_size=batch, \n",
    "                    epochs=200,\n",
    "                    )\n",
    "plot_model(baseline_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, accuracy_score, classification_report\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.python.keras.saving import hdf5_format\n",
    "from keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "import h5py, itertools, collections\n",
    "import itertools\n",
    "from keras.applications.efficientnet import EfficientNetB0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining your model here:\n",
    "i = 2\n",
    "model = models.Sequential()\n",
    "model.add(keras.Input(shape=dataset.image_size)) \n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255))\n",
    "model.add(EfficientNetB0(weights='imagenet', include_top=False))\n",
    "#Dense part\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(num_classes[i], activation='softmax'))\n",
    "# Print a summary of the model\n",
    "loss = keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history_baseline_model = model.fit(dataset.X_train, \n",
    "                    dataset.y_train[i],\n",
    "                    validation_data = (dataset.X_val, dataset.y_val[i]),\n",
    "                    batch_size=batch, \n",
    "                    epochs=200,\n",
    "                    )\n",
    "plot_model(baseline_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, accuracy_score, classification_report\n",
    "from tensorflow.keras import models, layers, optimizers\n",
    "from tensorflow.python.keras.saving import hdf5_format\n",
    "from keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "import h5py, itertools, collections\n",
    "import itertools\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "##################\n",
    "# Verifications:\n",
    "#################\n",
    "print('GPU is used.' if len(tf.config.list_physical_devices('GPU')) > 0 else 'GPU is NOT used.')\n",
    "print(\"Tensorflow version: \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Split train and validation.\n",
    "'''\n",
    "# We define the size of input images to 128x128 pixels.\n",
    "image_size = (256, 256)\n",
    "# We define the batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Create an image generator with a fraction of images reserved for validation:\n",
    "image_generator = ImageDataGenerator(\n",
    "                                     validation_split=0.5)\n",
    "\n",
    "# Now, we create a training data iterator by creating batchs of images of the same size as \n",
    "# defined previously, i.e., each image is resized in a 64x64 pixels format.\n",
    "train_ds =  DirectoryIterator(\n",
    "    \"dataset/\",\n",
    "    image_generator,\n",
    "    class_mode='categorical',\n",
    "    seed=1,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    subset = 'training',\n",
    ")\n",
    "\n",
    "# Similarly, we create a validation data iterator by creating batchs of images of the same size as \n",
    "# defined previously, i.e., each image is resized in a 64x64 pixels format.\n",
    "val_ds = DirectoryIterator(\n",
    "    \"dataset/\",\n",
    "    image_generator,\n",
    "    class_mode='categorical',\n",
    "    seed=1,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    subset = 'validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# We save the list of classes (labels).\n",
    "class_names = list(train_ds.class_indices.keys())\n",
    "\n",
    "# We also save the number of labels.\n",
    "num_classes = train_ds.num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.ResNet50(input_shape=image_size + (3,),\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "# base_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining your model here:\n",
    "model = models.Sequential()\n",
    "# model.add(keras.Input(shape=image_size + (3,))) \n",
    "# model.add(layers.experimental.preprocessing.Rescaling(1./255))\n",
    "# model.add(VGG19(input_shape=image_size + (3,), include_top=False, weights=\"imagenet\"))\n",
    "\n",
    "model.add(base_model)\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "# Print a summary of the model\n",
    "model.summary()\n",
    "\n",
    "base_learning_rate = 0.0001\n",
    "model.compile(optimizers.Adam(learning_rate = base_learning_rate),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the trining by defining the number of epochs to train, the traing set and the validation set.\n",
    "history = model.fit(train_ds, epochs=100,\n",
    "    validation_data=val_ds,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "name": "H_CNN_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
